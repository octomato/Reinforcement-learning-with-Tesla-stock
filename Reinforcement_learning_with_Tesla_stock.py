# -*- coding: utf-8 -*-
"""RNN, Reinforcement learning w/ Tesla stock.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sDspYg3mg0cLIicmFsH9EfNKp78gRuD1

### 0 Upgrade library if facing `RemoteDataError`
"""

!pip install --upgrade pandas-datareader
!pip install --upgrade pandas

"""### 1. Install and import dependencies"""

!pip install tensorflow-gpu==1.15.0 tensorflow==1.15.0 stable-baselines gym-anytrading gym

# Gym library: https://github.com/AminHP/gym-anytrading
import gym
import gym_anytrading

# DummyVecEnv is a wrapper to wrap trading environment for stable_baselines
from stable_baselines.common.vec_env import DummyVecEnv
# A2C library wiki https://github.com/Stable-Baselines-Team/stable-baselines
# Original paper: https://arxiv.org/abs/1602.01783
from stable_baselines import A2C

import numpy as np
import pandas as pd
import pandas_datareader as web
from matplotlib import pyplot as plt

"""### 2. Import data & visualize

##### 2.1 Import stock data
"""

# This is the code to use local data
# df = pd.read_csv('YOUR LOCAL OR REMOTE CSV FILE')

df = web.DataReader('TSLA', data_source = 'yahoo', start = '2020-04-04', end = '2022-04-04')
df

"""##### 2.2 Visualize stock data"""

# Visualize the closing price
plt.figure(figsize=(16, 8))
plt.title('Close Price History', fontsize = 25)
plt.plot(df['Close'])
plt.xlabel('Date', fontsize = 18)
plt.ylabel('Colse Price USD($)', fontsize = 18)
plt.show()

"""##### 2.3 (Optional) Visualize a random step"""

stocks_env = gym.make('stocks-v0', df = df, frame_bound=(15, 400), window_size = 15)
# stocks_env.prices
# stocks_env.signal_features
# stocks_env.action_space

# Stocks environment re-init
state = stocks_env.reset()
while True:
  # Here take random steps
  action = stocks_env.action_space.sample()
  n_state, reward, done, info = stocks_env.step(action)
  if done:
    break

plt.figure(figsize=(16,8))
plt.cla()
# Show all trades in stocks_env
stocks_env.render_all()
plt.title('Trade History', fontsize = 25)
plt.xlabel('Bound', fontsize = 18)
plt.ylabel('Colse Price USD($)', fontsize = 18)
plt.show

"""### 3. Build Environment and Train"""

env_builder = lambda: gym.make('stocks-v0', df = df, frame_bound = (15, 400), window_size = 15)
env = DummyVecEnv([env_builder])

predict_model = A2C('MlpLstmPolicy', env, verbose = 0)
predict_model.learn(total_timesteps = 600000)

"""### 4. Evaluation"""

evaluation_env = gym.make('stocks-v0', df = df, frame_bound=(400, 504), window_size = 15)
observation = evaluation_env.reset()
while True: 
    # Reshape the observation for the non-vectorized environment
    observation = observation[np.newaxis, ...]
    action, _states = predict_model.predict(observation)
    observation, rewards, done, info = evaluation_env.step(action)
    if done:
        print("Predict Result:", info)
        break

plt.figure(figsize=(15,6))
plt.cla()
evaluation_env.render_all()
plt.title('Predict Result', fontsize = 25)
plt.xlabel('Bound', fontsize = 18)
plt.ylabel('Colse Price USD($)', fontsize = 18)
plt.show()

"""### Optimize

- Limitation

- Fixed Window Size VS Increasing Window Size

- Meta-Labeling

"""